{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "scrapy库—功能强大的网络爬虫库\n",
    "\n",
    "一、安装：\n",
    "使用命令行—pip install scrapy(与其他库的安装类似)\n",
    "\n",
    "注意：\n",
    "\n",
    "1、本次安装出现的问题—Twisted库未能成功安装\n",
    "   解决方法：从http://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted下载对应whl文件\n",
    "             在命令行将目录切换到下载的目录下\n",
    "             使用pip install twisted下载的whl文件名即可完成安装\n",
    "          \n",
    "2、安装完成可在命令行使用 scrapy -h查看安装效果\n",
    "\n",
    "二、scrapy—并非函数功能库，而是一个爬虫框架\n",
    "\n",
    "1、爬虫框架：实现爬虫功能的一个软件结构和功能组件集合\n",
    "             是一个半成品（类似于模板），能够帮助用户实现专业网络爬虫\n",
    "          \n",
    "2、框架结构：“5+2”结构—5个主体部分和2个中间件\n",
    "\n",
    "5个主体—ENGINE模块（已有的功能实现，用户无需编写）\n",
    "         SCHEDULER模块（已有的功能实现，用户无需编写）\n",
    "         ITEM PIPELINES模块（需用户编写，该模块用来对提取的信息进行后处理）\n",
    "         SPIDERS模块（需用户编写，该模块用来向整个框架提供要访问的url，同时要解析从网络上获得的内容）\n",
    "         DOWNLOADER模块（已有的功能实现，用户无需编写）\n",
    "         \n",
    "2个中间件—ENGINE模块与SPIDERS模块之间\n",
    "           ENGINE模块与DOWNLOADER模块之间\n",
    "           \n",
    "3、数据流—提交的爬虫请求、抓取的数据等在这个结构中流动形成\n",
    "\n",
    "三条主要的数据流：\n",
    "\n",
    "1)、从SPIDERS模块—ENGINE模块—SCHEDULER模块\n",
    "    ENGINE模块从SPIDERS模块中获取到用户爬取的请求request，随后将其转发给SCHEDULER模块\n",
    "    SCHEDULER负责对爬取请求进行调度\n",
    "    \n",
    "2)、从SCHEDULER模块—ENGINE模块—DOWNLOADER模块—ENGINE模块—SPIDERS模块\n",
    "    ENGINE模块从SCHEDULER获取下一个要爬取得网络请求（此时的请求为真实的要去网络上爬取得请求），随后通过中间件发送给DOWNLOADER模块\n",
    "    DOWNLOADER获取该请求后即连接真实网页进行爬取，爬取完成后将爬取得内容Reponse由ENGINE模块发送给SPIDERS模块\n",
    "    \n",
    "3)、从SPIDERS模块—ENGINE模块—ITEM PIPLINES模块、SCHEDULER模块\n",
    "    SPIDERS模块处理来自DOWNLOADER模块的Reponse内容，即从网络中爬取得相关内容，处理后会产生两个数据类型：爬取项（items）、新的爬取请求（即获取的链接中有感兴趣的内容），随后将其发送给ENGINE模块\n",
    "    ENGINE模块收到这两类数据类型后，将爬取项（items）发送给ITEM PIPLINES模块\n",
    "                                    将新的爬取请求request发送给SCHEDULER模块进行调度，为后期处理及再次爬取提供新的来源 \n",
    "                                    \n",
    "以上三种数据流中，ENGINE模块控制各个模块的数据流，并且不断从SCHEDULER模块中获取真实要爬取得请求并将其发送给DOWNNLOADER模块\n",
    "\n",
    "整个scrapy爬虫框架的执行是从SPIDERS模块向ENGINE模块发送第一个请求开始，直到完成所有请求并对抓取内容进行处理放到ITEM PIPLINES模块中为止，即框架入口为SPIDERS模块，出口位ITEM PIPLINES模块\n",
    "\n",
    "3、由于scrapy爬虫框架并不需要完整、大片代码编写，只需在SPIDERS模块和ITEM PIPLINES模块中进行编写，因此将该种对已有框架进行编写的方式称为配置。\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
